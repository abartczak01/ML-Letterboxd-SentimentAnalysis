{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from langdetect import detect, LangDetectException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to Letterbox not having its offical API yet the data was scraped using tool Beautiful Soup. Reviews on the Letterboxd can be sorted in 5 different orders: newest first, earliest first, most popular first, highest ratings first, lowest rating first. For every sort order the maximum pages number that can be viewed is 256. To get maximum amount of data 256 pages were scraped for every sort order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing involved filtering out non-English reviews not marked with 'this review may contain spoilers,' converting dates to the appropriate format, and removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://letterboxd.com/film/in-the-mood-for-love/reviews/  - newest\n",
    "# https://letterboxd.com/film/in-the-mood-for-love/reviews/by/added-earliest/ - earliest\n",
    "# https://letterboxd.com/film/in-the-mood-for-love/reviews/by/activity/ - most popular\n",
    "# https://letterboxd.com/film/in-the-mood-for-love/reviews/by/entry-rating/ - highest rating\n",
    "# https://letterboxd.com/film/in-the-mood-for-love/reviews/by/entry-rating-lowest/ - lowest raring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date_str):\n",
    "    # Convert date from format '13 Jun 2024' to 'YYYY-MM-DD'\n",
    "    try:\n",
    "        date_obj = datetime.strptime(date_str, \"%d %b %Y\")\n",
    "        if date_obj.year > 2500:   # niektore lata sa wyzsze niz obecna data, kalendarz buddyjski, 543 lata do przodu\n",
    "            print(date_obj)\n",
    "            date_obj = date_obj.replace(year=date_obj.year - 543)\n",
    "            print(date_obj, '\\n=========')\n",
    "        return date_obj.strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        return date_str  # Return the original string if there's an error in conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(movie_title, limits=[1, 257]):\n",
    "    all_reviews = []\n",
    "    all_dates = []\n",
    "    all_ratings = []\n",
    "    # endpoints = [\"by/added-earliest/\"]\n",
    "    endpoints = [\"\", \"by/added-earliest/\", \"by/activity/\", \"by/entry-rating/\", \"by/entry-rating-lowest/\"]\n",
    "    base_url = f\"https://letterboxd.com/film/{movie_title}/reviews/\"\n",
    "    for endpoint in endpoints:\n",
    "        # jest dostępne maksymalnie 256 stron\n",
    "        for i in range(limits[0], limits[1]):\n",
    "            # print(i, endpoint)\n",
    "            url = base_url + endpoint\n",
    "            if i != 1:\n",
    "                url += f\"page/{i}/\"\n",
    "            try:\n",
    "                data = requests.get(url)\n",
    "                data.raise_for_status() \n",
    "                soup = BeautifulSoup(data.content, 'lxml')\n",
    "                film_details = soup.find_all(class_=\"film-detail\")\n",
    "\n",
    "                for detail in film_details:\n",
    "                    # Find review element\n",
    "                    review_element = detail.find(class_=\"body-text -prose collapsible-text\")\n",
    "                    review_text = \"\"\n",
    "                    if review_element:\n",
    "                        review_text = review_element.find(\"p\").text\n",
    "\n",
    "                    # Check if the review is in English\n",
    "                    if is_english(review_text):\n",
    "                        all_reviews.append(review_text)\n",
    "\n",
    "                        # Find date element\n",
    "                        date_text = \"\"\n",
    "                        date_element = detail.find(class_=\"_nobr\")\n",
    "                        if date_element:\n",
    "                            date_text = date_element.text\n",
    "                            print(date_text, convert_date(date_text))\n",
    "                        all_dates.append(convert_date(date_text))  # Convert date here\n",
    "\n",
    "                        # Find rating element\n",
    "                        rating_text = \"\"\n",
    "                        rating_element = detail.find(class_=lambda x: x and x.startswith('rating -green rated-'))\n",
    "                        if rating_element:\n",
    "                            # Extract the numerical rating from the class name\n",
    "                            rating_class = rating_element['class']\n",
    "                            for cls in rating_class:\n",
    "                                if cls.startswith('rated-'):\n",
    "                                    rating_text = cls.split('-')[-1]\n",
    "                                    break\n",
    "                        all_ratings.append(rating_text)\n",
    "            except Exception as e:\n",
    "                print(f\"Error on page {i} with endpoint '{endpoint}': {e}\")\n",
    "\n",
    "    # Create DataFrame and save to CSV\n",
    "    reviews_data = pd.DataFrame({\n",
    "        'Date': all_dates,\n",
    "        'Review': all_reviews,\n",
    "        'Rating': all_ratings\n",
    "    })\n",
    "\n",
    "    csv_filename = f\"{movie_title}_reviews.csv\"\n",
    "    reviews_data.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "    print(f\"Reviews, dates, and ratings have been saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_reviews(\"american-psycho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_reviews(\"fight-club\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_reviews(\"blade-runner-2049\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_reviews(\"drive-2011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(title):\n",
    "    df = pd.read_csv(f\"data/{title}_reviews.csv\")\n",
    "    og_shape = df.shape[0]\n",
    "    print(f\"Liczba wierszy dla {title}:\", df.shape[0])\n",
    "    df = df[df['Review'] != \"This review may contain spoilers. I can handle the truth.\"]\n",
    "    df = df.drop_duplicates(subset=['Date', 'Review', 'Rating'])\n",
    "    print(f\"Liczba wierszy w {title} po usunięciu duplikatów i schowanych recenzji:\", df.shape[0])\n",
    "    df.to_csv(f\"data/{title}_fixed.csv\", index=False)\n",
    "    return df, og_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba wierszy dla blade-runner-2049: 10737\n",
      "Liczba wierszy w blade-runner-2049 po usunięciu duplikatów i schowanych recenzji: 9296\n",
      "Liczba wierszy dla drive-2011: 10626\n",
      "Liczba wierszy w drive-2011 po usunięciu duplikatów i schowanych recenzji: 9558\n",
      "Liczba wierszy dla fight-club: 10728\n",
      "Liczba wierszy w fight-club po usunięciu duplikatów i schowanych recenzji: 9048\n",
      "Liczba wierszy dla american-psycho: 10452\n",
      "Liczba wierszy w american-psycho po usunięciu duplikatów i schowanych recenzji: 9279\n"
     ]
    }
   ],
   "source": [
    "titles = [\"blade-runner-2049\", \"drive-2011\", \"fight-club\", \"american-psycho\"]\n",
    "dfs = []\n",
    "before = []\n",
    "after = []\n",
    "for name in titles:\n",
    "    df, og_shape = preprocessing(name)\n",
    "    dfs.append(df)\n",
    "    before.append(og_shape)\n",
    "    after.append(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles: ['blade-runner-2049', 'drive-2011', 'fight-club', 'american-psycho']\n",
      "before: [10737, 10626, 10728, 10452] 42543\n",
      "after: [9296, 9558, 9048, 9279] 37181\n",
      "usunięto 12.60371859060245% wierszy\n"
     ]
    }
   ],
   "source": [
    "print(\"titles:\", titles)\n",
    "print(\"before:\", before, sum(before))\n",
    "print(\"after:\",  after, sum(after))\n",
    "print(f\"removed rows: { (sum(before)-sum(after))/sum(before) * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
